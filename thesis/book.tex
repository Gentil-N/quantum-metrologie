 \documentclass[12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[a4paper,width=155mm,top=20mm,bottom=20mm]{geometry}
\graphicspath{ {images/} }

\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{esvect}
\usepackage{stmaryrd}
\usepackage{bbold}

\usepackage{mathtools}
\DeclarePairedDelimiter\bra{\langle}{\rvert}
\DeclarePairedDelimiter\bbra{\langle\langle}{\rvert}
\DeclarePairedDelimiter\ket{\lvert}{\rangle}
\DeclarePairedDelimiter\kket{\lvert}{\rangle\rangle}
\DeclarePairedDelimiterX\braket[2]{\langle}{\rangle}{#1\,\delimsize\vert\,\mathopen{}#2}
\DeclareMathOperator{\Tr}{Tr}



\begin{document}
\title{Title}
\author{Neven Gentil}
\date{May 2024}
\maketitle

\begin{abstract}
My very nice abstract
\end{abstract}

\chapter{Theoretical Development}
\section{Optical Cavity}
\paragraph{}
We firstly introduce one of the most common object of quantum optic, namely, the \textit{optical cavity}. It is mainly constitued of two mirrors mounted perpendicularly to the optical axis at a certain distance from each other. The idea behind this simple setup is to select a discret range of wavelengths defined by the space between the mirrors. 

Indeed, one can modelize the cavity as an one-dimensional box, then apply the wave equation $ \square \vv{E} = 0$ where $\square$ is the d'Alembertian operator and $\vv{E}$ the electric field's amplitude, together with the Maxwell equation $\nabla \cdot \vv{E} = \partial _x E = 0$. As the wave must vanish at the boundaries of the box (meaning that the energy cannot propagate outside of the box's region) one would find that the solutions are linear combinations of sinuzoidale functions, each of them having a spatial frequency multiple of $\frac{\pi}{L}$ where $L$ denotes the length of the box/cavity. We shall consider that our model lies into a vacuum chamber, leading to the refractive index $n=1$ for the void and the well known constant $ c$ for the speed of light. Then, thanks to the relation $\omega = ck$ we see that the angular frequency is also quantized.\footnote{R.Loudon derives rigorous equations in sections 1.1 and 1.2 of \textit{Quantum Theory of Light}.} It is important to note that the argument is valid for other refractive index and higher dimensions (i.e in 2D, 3D, ...).

With a more pragmatic point of view, one can think of this wavelength selection as an interferometer. In fact, let's imagine for a while that we emplace a cavity in front of the sun, fast enough to capture a beam of sunlight. Then we stop the clock before further propagation. Mathematically, the waves which are differents from the selective frequency vansih instantaneously, because of the presence of the cavity. However, physically, the full spectrum of the sun still resides between the two mirrors. Then if we run the clock again, the light is reflected from the back mirror. As we captured a continous stream, the $\pi$-dephased reflected light encouters the incoming light: interference happens and after a couple of round-trips, only the waves generating an in-phase match at each round-trip (i.e with a space-frequency or wave-number $\frac{n\pi}{L}, n\in \llbracket 0, +\infty \llbracket $) remains by constructive interference, creating standing waves of the same frequency. On the other hand, all the other frequencies produce at reflection, in average on some round-trips, a \textit{random-like} phase difference: the sum shall give a null coefficient in term of amplitude for those given frequencies. Although this is a simple explanation, two things are important to note:
\begin{itemize}
  \item For the constructive interference case, we say that we need to be in-phase after one round-trip, meaning that after two reflections, which happens after hitting both back and front mirrors of the cavity, the wave must replicate the same amplitude at any position. However, the electric field is not static but moves in space. Then, it becomes more evident that twice the length of the cavity must be a multiple of the frequency in order to give the exact same phase, even with a space-motion of the wave.
  \item  For all the other frequencies, the phase difference is not random but actually well behaved. Nevertheless, After a couple of round-trip, the set of generated phase difference is unformly distributed among $ \left[ -\pi, \pi \right] $ reproducing a sort of randomness.
\end{itemize}

Thereby, that is why the device created by C.Fabry and A.Pérot in 1899 is called an \textit{interferometer} as, in their case, the light hit the mirrors with an angle, creating the famous pattern of fringes. Equivalently, this category of instrument is often named \textit{resonator} as the amplitude of the electric field is enhanced in the case of resonance with the cavity or decreases in other cases: by conception, it can be modelized as a classical harmonic oscillator or with the quantum equivalent. \footnote{As we will see later, each resonant frequency owns a linewidth as a classical oscillator, in contrary to the quantum equivalent where the energy ladders (i.e the frequencies, in virtue of the relation $ \hbar \omega$) are well defined.}

In real experiments, the device is static and one prefers to let the light enter partially, to feed the cavity, and exit partially to collect the selected waves. In that way, we use \textit{partially reflective} mirrors parametrized by an electric field reflection coefficient $r$ and an electric field transmission coefficient $t$ obeying the relation $r^2 + t^2 = 1$ (the squared terms are the respective coefficient for the intensityof the field), meaning that all the absorbed energy must be re-emitted by the mirror, which is of course not fully true as some amount of the energy is transformed into heat. However, current manufacturers creates mirros with less than $0.01\%$ of loss and the above formula is sufficient for most of the applications.

The most commonly used approach to express the cavity response is the Airy distribution which represents the intensity ratio between the internal electric field and the \textit{launching} electric field (i.e the amount of \textit{feeding}-field succeding to transmit through the first mirror and penetrate the cavity), in function of the phase accumulated by round-trip:
\begin{equation}
\label{eqairy}
\textrm{Airy distribution} : A(\phi) \stackrel{\text{def}}{=} \frac{I_{circ}}{I_{launch}}
\end{equation} In other words, it just makes the link between the enhancment factor of the cavity field and the constructive-destructive interference phase pattern. In order to derive it, we shall use the circulating field approach \footnote{A. E. Siegman, section 11.3, \textit{Lasers}}, represented in Fig (add figure!) and constitued of:
\begin{itemize}
	\item A launching electric: $ E_{launch} $
	\item A round-trip electric field which is the field after one complete round-trip: one reflection on the back mirror plus another on the front mirror. We call it $ E_{RT}$
	\item A circulating electric field which is the sum of the launched field and the round-trip one: $ E_{circ} =  E_{launch} + E_{RT}$. It is by definition the internal electric field.
	
\end{itemize}

Here, we use the phasor representation where the electric field (a real analytic signal) is splitted into two conjugate complex numbers:
\begin{align} 
\label{eq1}
E(x, t) &= \overline{E}(x, t) + \overline{E}^*(x, t) \quad \textrm{s.t} \quad E(x, t) \in \mathbb{R}, \quad \overline{E}(x, t) \in \mathbb{C} \\\label{eq2}
&= 2 \Re \{  \overline{E}(x, t) \} 
\end{align}
Then, we consider fields evolving in time and in space along the optical axis $ x$. Moreover, one considers only the amplitude of the fields and deals with scalar equation. However one can assume linearly polarized input field to get the same mathematical treament but the Airy distribution is valid for any kind of polarization and can be genelarized for vectorial equations instead (i.e at higher dimension). Note that \eqref{eq1} is not a definition sign "$\stackrel{\text{def}}{=}$" as an analytic signal can be written is that form.\footnote{More explanations about the hypothesis and what an analytic signal implies in section ??}

Rewriting the equation for the circular field gives:
\begin{equation}
2\Re\{\overline{E}_{circ}\} = 2\Re\{\overline{E}_{launch}\} + 2\Re\{\overline{E}_{RT}\}
\end{equation}
which, by linearity and analyticity of the signal, is equivalent to:
\begin{equation}
\label{eqecirc}
\overline{E}_{circ} = \overline{E}_{launch} + \overline{E}_{RT}
\end{equation}

Now, one can express the round-trip field from the circular one, dephased by a certain angular amount. Indeed, one knows that each mirror add a phase of $\pi$ to the original field and the amplitude is modulated by the reflection factor $R$. As a field of space-frequency $k$ and propagating over a distance $l$ is shifted by:
\begin{equation}
\omega \times \textrm{"propagation time"} = \omega \times \frac{l}{c}
\end{equation} 
Then, after a complete round-trip, one obtains for the "RT" field a total angular shift of:
\begin{equation}
2\phi \stackrel{\text{def}}{=} \frac{2L}{c}\omega + 2\pi
\end{equation} 
Thereby:
\begin{equation}
\label{eqrt}
\overline{E}_{RT} = r_1 r_2 e^{-i2\phi} \overline{E}_{circ}
\end{equation}
where $r_{1,2}$ are the reflection coefficients of front and back mirror respectively. In other words, instead of propagating the field from its original value $ \overline{E}_{circ}$ through time or space to get a phase, we compute the relative phase $\phi$ from the length of the cavity $L$ with the field's frequency $\omega$.

One can highlight that for a caracteristic space-frequency of the cavity $k=\frac{n\pi}{L}$, we have:
\begin{equation}
\label{phimodif}
2\phi = \frac{2L}{c} \times \frac{cn\pi}{L} + 2\pi = 2\pi(n + 1) \quad \equiv \quad 0 \quad [2\pi]
\end{equation}
meaning that those frequencies does not generate any phase shift after one complete round-trip, involving constructive inteferences then standing waves.

Putting \eqref{eqrt} in \eqref{eqecirc} leds to:
\begin{equation}
\frac{\overline{E}_{circ}}{\overline{E}_{launch}} = \frac{1}{1 - r_1 r_2 e^{-i2\phi}}
\end{equation}
Then, one uses the relation $ I \simeq \vert\overline{E}\vert^2$, which is valid for an average of the intensity over some periods of the $\overline{E}$-field \footnote{See section ??} and by the definition \eqref{eqairy}, one obtains:
\begin{equation}
\label{airyformula}
A(\phi) = \frac{1}{(1 - r_1 r_2)^2 + 4 r_1 r_2 \sin^2(\phi)}
\end{equation}
Moreover, to get the actual distribution that we observe through the cavity, that is to say, the enhancment factor at the output of the cavity, we set:
\begin{equation}
\label{airyformulasec}
A'(\phi) = (1-r_1^2)(1-r_2^2)\times A(\phi)
\end{equation}
where one uses the intensity transmission coeffcients $t_{1,2}^2 = 1-r_{1,2}^2$.Now, in order to sketch the function, independent of the size of the cavity $L$, we shall use the third term of the equality \eqref{phimodif} to reparametrize the round-trip dephasing variable $\phi$:
\begin{equation}
\label{phidef}
\phi = \pi(x+1) \quad \equiv \quad \pi x \quad [\pi]
\end{equation}
where the integer variable $n$ has been replaced by the continuous one $x \in \mathbb{R}$ so that one can also investigate the behavior of the enhancment factor $A'(\phi) \sim A'(x)$ away from the resonant frequencies. Fig (??) is a normalized drawing\footnote{One divides the whole graph by $A'(0)$} of the airy distribution for a short amount of negative and positive resonant frequencies through a couple of reflexion coefficient $r_{1,2}$. 

(add figure!)

To clarify, the abscisse coordinate is the factor quantity between two caracteristic frequencies $\frac{n\pi}{L}$, which can be equivalently spatial or temporal as we get ride of the constant $c$ in our calculation: then $x$ is a frequency divided by the free spectral range (FSR) In other words, for $x=\frac{1}{2}$, one gets the enhancment factor $A'$ for exactly a frequency halfway between two resonances, whereas $x=1$ gives the $A'$ factor for the first resonant frequency of the cavity.\footnote{One could say that the first resonant frequency is $x=0$ according to the figure or even the formula \eqref{airyformula} itslef. However, $x=0$ also means $n=0$: the launched field would have null frequency, which is not a physical solution.}

From those previous results, we can now define the \textit{full width at half maximum} (FWHM) which approximately represents how broad is the range around a resonant frequency where the field is modulated by more than one-half. Thanks to \eqref{airyformula}, one obtains $ A(0) / 2$ when the denominator respects:
\begin{equation}
(1 - r_1 r_2)^2 = 4 r_1 r_2 \sin^2(\Delta\phi) \Rightarrow \Delta\phi = \arcsin \left(\frac{1 - r_1 r_2}{2\sqrt{r_1r_2}} \right)
\end{equation}
with, in virtue of \eqref{phidef}:
\begin{equation}
\Delta\phi = \frac{\pi}{2}\Delta\nu
\end{equation}
where $\textrm{FWHM} \stackrel{\text{def}}{=} \Delta\nu$.

Finally, one can sketch the FWHM in fonction of the mirror reflectivities $r_{1,2}$ and obtains Fig ??

(add figure)

Two important points are noticeable:
\begin{itemize}
	\item The linewidth of a cavity is invertly dependent on the mirrors reflectivity. In other words, more transmitive are the mirrors, broader is the frequency range around resonances, giving a \textit{less selective} cavity, and reciprocally. Then, two perfeclty reflective mirrors allow the FWHM to tend to zero: the cavity selects only and exactly the resonant frequencies $\frac{n\pi}{L}$. Formally, the \textit{selectivity} of a cavity is defined by its \textit{finesse} which reads $F \stackrel{\text{def}}{=} \frac{\Delta\nu}{\textrm{FSR}}$: one normalizes the linewidth by the distance (in term of frequency) separating two resonances. On Fig ??, as FSR is unity then the ordinate axis is also the finesse by definition.
	\item The function modelizing the FWHM tends to infinity below a certain value which can be evaluated to approximately $r_1r_2 \approx 0.17$. That is due to the behavior of the $\arcsin$ which is not defined beyond $x=1$ for $x \in \mathbb{R}^+$. 
\end{itemize}

Nevertherless, it is always possible to build an experiment involving mirrors with high-losses (i.e very low reflection or very high transmission), without the output frequency going crazy. Thereby, what happens? Well, this is a limitation case of this \textit{Airy}-model and in the common scientific description of a cavity, one utilizes the Lorentzian approach where one defines a coherent time of the light from the reflection coefficient and the cavity length, then gets a differential rate equation of the amount of photons (i.e an exponential decay of the electric field) which, by virtue of the Fourier transform, gives a Lorentzian as a spectrum around one resonant frequency. Then, to obtain the full cavity spectrum, one has to place each Lorentzian of a given resonance on top of each other on the same graph.\footnote{Note that when treating the spontaneaous emission of an atom (or more formally, a two-level atomic system), one also deals with differential rate equations, which represents the exponential lifetime decay of the excitation, giving a Lorentzian as a spectrum: longer it takes to the system to decay, broader is the bandwidth. However, the analogy stops here: for a cavity, the whole electric field spectrum is affected by the linewidth, whereas, for a two-level atom, the spectrum represents the frequency uncertainty as the atom can spontaneously emit a photon with frequency slightly different from what the atom has been excited with.}

The Lorentzian model is highly faithfull to the real world experiment for all the possible reflective coefficients and tends to give the same caracteristic values (linewidth, finesse, ...) than the Airy-model from half to full reflective mirrors. However, it may seem to be less intuitive even if the derivation is straigthforward and, after all, the goal here was to show the principle of interference inside a cavity due to the round-trip dephasing term.

Finally, the next step for an optical cavity is, as many of physical systems, to interact with its environment. In other words, what happens if one adds an element, let's say atoms, inside of it? Well, this is basically the principle of lots of current experiments and avdvanced optical tools, namely the \textit{LASER} among others, and the next section is decidated to the mathematical formulation of one first model for a cavity filled with a gain medium.

\section{Jaynes-Cummings model}
\paragraph{}
As an introduction, it is important to remind that the Jaynes-Cummings (JC) approach is no more no less than a model, which means that it is based on some hypothesis and has limitations which leads to refinements for more complex physical systems. In the current section, we shall present as wide as possible the principles of this model which will be the foundments of all the next derivated/evoluted models\footnote{As written, the JC-model may seem to be a pre-model or even a \textit{toy tool} in view of introducing other legitimate models. Nevertheless, the JC-model is an actual physical approach, currently used for real use-cases in Quantum Optics, especially whith single atom interactions.}, even if the section is not supposed to be exhaustive but only a reference-like for further theoretical developments.

First of all, our system is composed of:
\begin{itemize}
	\item An electric field inside a cavity: this E-field is quantized and can only be a superposition of resonances.
	\item A single two-level system: this system has a structure of ground-excited state and can represent a transition of an atom for example.
\end{itemize}

When quantizing the the E-field inside of a box of volume $V = L^3$ (i.e the cavity in three dimensions), one finds that the corresponding hamiltonian operator is [??Loudon p143]:
\begin{align}
\hat{H}_{cav} &= \int_{cavity} \left[\epsilon_0 \hat{E}(\vv{r}, t) \cdot \hat{E}(\vv{r}, t) + \mu_0^{-1} \hat{B}(\vv{r}, t) \cdot \hat{B}(\vv{r}, t)\right] \quad dV\\
&= \sum_{\vv{k}} \sum_{\lambda} \hbar \omega_{c,\vv{k}} \left( \hat{a}_{\lambda \vv{k}}^\dag \hat{a}_{\lambda \vv{k}} + \frac{1}{2} \right)
\end{align}
where $\hat{E}(\vv{r}, t)$ and $\hat{B}(\vv{r}, t)$ are respectively the electric and magnetic operators; $\epsilon_0$ and $\mu_0$ the electric and magnetic susceptibility of the vacuum respectively, $\omega_{c,\vv{k}}$ the frequency mode; $\lambda=\pm 1$ the polarization; $\hat{a}_{\lambda \vv{k}}^\dag$ with $\hat{a}_{\lambda \vv{k}}^\dag$ the ladders operator of the field.

Now, we define the electric field as exactly a unique mode with a unique polarization. Thereby:
\begin{equation}
\hat{H}_{cav} = \hbar \omega_c \left( \hat{a}^\dag \hat{a} + \frac{1}{2} \right)
\end{equation}
where we dropped the subscripts $\vv{k}$ and $\lambda$. In other words, we represent the electric wave as a perfectly coherent field which fits a resonance of the cavity at frequency $\omega_c$. As we can see, this one-mode cavity system is treated as a quantum harmonic oscillator.

Then comes the choice of the model for the ground-excited system. Sometimes, in the litterature [??MandelWolf], one utilizes another quantum harmonic oscillator with bosonic modes, namely:
\begin{equation}
\label{sec_bosonic_mw}
\hat{H}_{atom} = \hbar \omega_a \left( \hat{b}^\dag \hat{b} + \frac{1}{2} \right)
\end{equation}
where $\hat{b}$ is the bosonic operator of the two-level system. However, this model allows mutliple excited levels and the energy of the atom-system is artifically restrained to the first two levels.

In fact, an advantageous choice is to use the spin-half quantum system:
\begin{equation}
\hat{H}_{atom} = \hbar \omega_a \hat{\sigma_z}
\end{equation}
where $\hat{\sigma_z}$ is the third Pauli matrix.
This model allows us to use the spin-down $\ket{\downarrow}$ as the ground state with an energy: \begin{equation}
E_g \stackrel{\text{def}}{=} \bra{\downarrow}\hat{H}_{atom}\ket{\downarrow} = -\hbar\omega_a
\end{equation}
and $\ket{\uparrow}$ as the excited state with an energy:
\begin{equation}
E_e \stackrel{\text{def}}{=} \bra{\uparrow}\hat{H}_{atom}\ket{\uparrow} = \hbar\omega_a
\end{equation} Moreover, the Pauli matrices can exponentiates to the Lie algebra of SU(2) then follows similar commutator relations, namely:
\begin{equation}
\label{sigma_commut}
{\displaystyle [\hat{\sigma} _{j},\hat{\sigma} _{k}]=2i\varepsilon _{jkl}\,\hat{\sigma} _{l}}
\end{equation} 
where $\varepsilon _{jkl}$ is the Levi-Civita symbol. For the ladder operators $\hat{\sigma}_{\pm}=\hat{\sigma}_x \pm i\hat{\sigma}_y$, one can esasily prove the following projections:
\begin{equation}
\label{sigmapm_rules}
\hat{\sigma}_+ \ket{\downarrow} = \ket{\uparrow} \quad\quad
\hat{\sigma}_- \ket{\downarrow} = 0 \quad\quad
\hat{\sigma}_- \ket{\uparrow} = \ket{\downarrow} \quad\quad
\hat{\sigma}_+ \ket{\uparrow} = 0 \quad\quad
\end{equation}
which means that one can excite a ground state or damp an excited state but one cannot excite an already excited state or damp a ground state: the spin-1/2 model is restrained to a pair of states by definition.\footnote{From an autor to another, the eigenvalues may differ from a constant (in particular by a factor of $2$). Keep in mind that the Pauli matrix operators are taken from $\hat{\sigma}_i = \frac{2}{\hbar}\hat{S}_i$ where $\hat{S}_i$ is the spin operator.}

Now that we got the hamiltonian operators for the cavity field and the two-level system, we use the tensor product in order to create a quantum system all-encompassing those two systems:
\begin{equation}
\hat{H}_{JC} = \hat{H}_{atom} \otimes \mathbb{1}_{cav,2} + \mathbb{1}_{atom,n} \otimes \hat{H}_{cav} + \hat{H}_{int}
\end{equation}
where $\mathbb{1}_{cav,2}$ and $\mathbb{1}_{atom,n}$ are the identity operators for the Hilbert-space of the cavity and the atom respectively. Naturally, by their definition the Hilbert-space of the atom is of dimension $2$ (i.e two states form the basis) whereas the Hilbert-space of the cavity is of dimension $n$ as the quantum harmonic oscillator is associated to a Fock-space of the same dimension (i.e one has $n$ possible different levels of energy for the electric field). In other words, we build another Hilbert-space of dimension $2n$ from two separated system.\footnote{$\hat{H}_{atom}$ and $\hat{H}_{cav}$ are often refered to the energy of the atom and the cavity field respectively, which is a bit tendencious as this is only true when one takes those two systems separately, but falls down as soon as we mix them and add the interaction term: the eigenvalues (i.e energies) with an interaction are very different from the eigenvalues of the separated systems. Moreover, a hamiltonian operator corresponds to the energy if and only if it is \textit{explicitly} independent of time (which is the case here but it is always nice to precise the reason).} We also defined $\hat{H}_{int}$ as an additional hamiltonian operator belonging to an Hilbert-space which is of dimension $2n$ by construction: this new term arises from the physical interaction of the two systems but not by the \textit{mixture} of the cavity and atom systems (i.e there is nothing related with the tensor product). This interaction term can be mathematically formulated with the electric field's acting on the dipole constitued by the atom:
\begin{equation}
\hat{H}_{int}  \stackrel{\text{def}}{=} -\hat{d}\cdot\hat{E}(\vv{r}, t)
\end{equation}
where $\hat{d}$ is the dipole operator in term spin-half operators (using Pauli matrices) and $\hat{E}$ the quantized electric field of the cavity. After centering the frame on the atom with $\vv{r} = 0$, the interaction hamiltonian transforms as:
\begin{equation}
\hat{H}_{int} = \hbar g \left[ (\hat{\sigma}_+ - \hat{\sigma}_-) \otimes (\hat{a}^\dag - \hat{a})\right]
\end{equation}
where $g$ is the coupling constant arising from multiple constant terms belonging to the dipole and electric operators: $g$ defines \textit{how strong/often} the cavity field and the atom will exchange energy.
Finally, one obtains the complete hamiltonian operator for the Jaynes-Cummings model:
\begin{align}
\hat{H}_{JC} &\stackrel{\text{def}}{=} \hat{H}_0 + \hat{H}_{int}\\
&= \hbar \omega_c \left( \hat{a}^\dag \hat{a} + \frac{1}{2} \right) \otimes \mathbb{1}_{cav,2} + \mathbb{1}_{atom,n} \otimes \hbar \omega_a \hat{\sigma_z} + \hbar g \left[ (\hat{\sigma}_+ - \hat{\sigma}_-) \otimes (\hat{a}^\dag - \hat{a})\right]\\
\label{hjc_original_frame}
&= \hbar \omega_c \hat{a}^\dag \hat{a} + \hbar \omega_a \hat{\sigma_z} + \hbar g \left[ (\hat{\sigma}_+ - \hat{\sigma}_-) (\hat{a}^\dag - \hat{a})\right]
\end{align}
where we omit the tensor product on the last line and remove the $\frac{1}{2}\hbar\omega_c$, which is only a choice of reference for the vacuum energy (i.e here we set zero). In the future, the \textit{atomic} operators will lies on the right of the \textit{field} operators in order to remind the implicit tensorial structure of the system.\footnote{Note that we can reverse the tensor product order as long as one does not involve the coefficient of the states and this artifical sort is only present to clarify the notation and equations.}

Then, we shall change the reference frame of the hamiltonian in order to deal only with the frequency difference $\Delta\omega \stackrel{\text{def}}{=} \omega_c - \omega_a$, called \textit{detuning}. It will be advantageous for the simulation part and also allow us to apply a very common approximation. In this way, we use a U(1) symmetry for the JC-hamiltonian in this manner:
\begin{align}
\hat{H}_{JC} &\rightarrow U\hat{H}_{JC}U^{-1} + i\hbar\dot{U}U^{-1}\\
\ket{\psi} &\rightarrow U\ket{\psi}
\end{align}
where $\ket{\psi}$ is a solution of the Schrödinger equation for the JC-hamiltonian; $U$ is a unitary operator with its inverse $U^{-1}$ belonging to its dual space, involving $U^{-1}=U^{\dag}$; $\dot{U}$ is the one-time derivative of $U$. It can be proven that the transformed hamiltonian and $U\ket{\psi}$ vector plugged into the Schrödinger equation, give the same equation as the JC-hamiltonian and $\ket{\psi}$. Thereby, if one finds a solution $\ket{\phi}$ of the transformed system, then $U^{\dag}\ket{\phi}$ gives $\ket{\psi}$ which is a solution of the original system.

In our case, we choose the unitary transformation as:
\begin{equation}
U \stackrel{\text{def}}{=} e^{\frac{i\omega_at}{\hbar}\hat{H}_0} = e^{i\omega_at(\hat{n} + \hat{\sigma}_z)}
\end{equation}
where we utilize the common photon number operator of the field, $\hat{n} = \hat{a}^{\dag}\hat{a}$. As the U(1) symmetry is essentially a rotation along the complex unitary circle, we explicitly choose here a rotation of $\omega_at$ which means that the transformed hamiltonian will be placed in the same frame as the atom: one calls this frame the \textit{rotating frame}.

From Annexe (??) one finally obtains the following parts for the transformed hamiltonian:
\begin{align}
i\hbar \dot{U} U^{\dag} &= -\hbar\omega_a(\hat{n} + \hat{\sigma}_z)\\
U\hbar \omega_c\hat{n} U^{\dag} &= \hbar\omega_c\hat{n}\\
U\hbar \omega_a\hat{\sigma}_z U^{\dag} &= \hbar\omega_a\hat{\sigma}_z\\
U\hbar g\hat{\sigma}_+\hat{a} U^{\dag} &= \hbar g\hat{\sigma}_+\hat{a}\\
U\hbar g\hat{\sigma}_-\hat{a}^{\dag} U^{\dag} &= \hbar g\hat{\sigma}_-\hat{a}^{\dag}\\
\label{rwa_1}
U\hbar g\hat{\sigma}_+\hat{a}^{\dag} U^{\dag} &= e^{2i\omega_at}\hbar g\hat{\sigma}_+\hat{a}^{\dag}\\
\label{rwa_2}
U\hbar g\hat{\sigma}_-\hat{a} U^{\dag} &= e^{-2i\omega_at}\hbar g\hat{\sigma}_-\hat{a}
\end{align}
As we shall us the detuning $\Delta\omega$ for the transformed hamiltonian instead of the respective cavity and atom frequency, it makes sense to write down a strong hypothesis on the system: $\omega_a \sim \omega_c$ which means that one assumes that the cavity and atom frequencies have the same order of magnitude. Thereby, the terms \eqref{rwa_1} and \eqref{rwa_2} are rotating extremely fast compared to our reference frame, about twice the cavity or atom frequency, and are qualified of \textit{anti-resonant}. Then, those terms average to zero over some cycles and can be discarded. This approximation is called the \textit{rotating wave approximation} (RWA).\footnote{Here, we firstly change the reference frame in order to introduce the RWA. However, this is not necessary. Indeed, the RWA only influence the interaction hamiltonian and one can apply this approximation directly in \eqref{hjc_original_frame} through the interaction picture evolution.}

At the end of the day, one finds the transformed hamiltonian:
\begin{equation}
\label{HJC}
\hat{H}_{JC} \rightarrow \hbar\Delta\omega\,\hat{n} + \hbar g \left(\hat{\sigma}_+ \hat{a} + \hat{\sigma}_- \hat{a}^{\dag} \right)
\end{equation}
that we rename by convenience and without ambiguity $\hat{H}_{JC}$. One may first notice that the atomic hamiltonian term vanished and only the field operator remains of $\hat{H}_0$: that is due to the new frame which \textit{follows} the atomic frequency, then the transformed $\hat{H}_{cav}$ is proportional to the detuning. It is also interesting to see how a \textit{generic} JC-state (i.e $\ket{\uparrow} \otimes \ket{n}$ or $\ket{\downarrow} \otimes \ket{n}$ which are also called \textit{bare states}) is influenced by the transformed interaction hamiltonian:
\begin{align}
\hat{H}_{int} \cdot \ket{\uparrow} \otimes \ket{n} &= \hbar g \left[ (\hat{\sigma}_+ \otimes \hat{a}) \cdot (\ket{\uparrow} \otimes \ket{n}) + (\hat{\sigma}_- \otimes \hat{a}^{\dag}) \cdot (\ket{\uparrow} \otimes \ket{n}) \right]\\
&= \hbar g \left[ \hat{\sigma}_+\ket{\uparrow} \otimes \hat{a} \ket{n} + \hat{\sigma}_- \ket{\uparrow} \otimes \hat{a}^{\dag} \ket{n} \right]\\
&= \hbar g \left[ 0 + \ket{\downarrow} \otimes \sqrt{n+1}\ket{n+1} \right]\\
&= \hbar g \ket{\downarrow} \otimes \sqrt{n+1}\ket{n+1} \stackrel{\text{def}}{=} \hbar g \sqrt{n+1} \ket{\downarrow, n+1}
\end{align}
where we used \eqref{sigmapm_rules}. Equivalently:
\begin{align}
\hat{H}_{int} \cdot \ket{\downarrow, n} &= \hbar g \left[ \hat{\sigma}_+ \hat{a} \ket{\downarrow, n} + \hat{\sigma}_- \hat{a}^{\dag} \ket{\downarrow, n} \right]\\
&= \hbar g \sqrt{n} \ket{\downarrow, n-1}
\end{align}
In other words, in the first case, an excited two-level system decays into its ground state, releasing a photon into the field (i.e the total energy is conserved), whereas in the second case, an atom \textit{at rest} absorbs a photon of the field and ends up in its excited state: this is intuitively how one may imagine the interaction between the atom and the cavity field system.

In order to solve the system evolution, one wants to diagonalize the hamiltonian by finding the eigenstates and the eigenvalues. It turns out that $\hat{H}_{JC}$ can be written by $2\times 2$ blocks in the JC-states:\footnote{The reason comes from the bare states being degenerated with eigenvalue $n+1$ when applied on the non-transformed base hamiltonian $\hat{H}_0$.}
\begin{equation}
\label{jc_block}
\hat{H}_{JC} = \bigotimes_n \begin{bmatrix}
\hbar \Delta\omega \, (n-1) & 2\hbar g \sqrt{n}\\
2\hbar g \sqrt{n} & \hbar \Delta\omega \, n
\end{bmatrix}
\end{equation}
where $n$ under the tensor product is the fock space dimension associated to the cavity system.

After diagonalizing each block of \eqref{jc_block} (Annexe ??), one finds the following egeinvalues and eigenstates:
\begin{align}
E_{n, \pm} &\stackrel{\text{def}}{=} \hbar\Delta\omega\,(n-\frac{1}{2}) \pm \frac{\hbar}{2}\sqrt{4g^2n + \Delta\omega ^2}\\
\ket{n, +} &\stackrel{\text{def}}{=} \cos\left(\frac{\theta_n}{2}\right) \ket{\uparrow, n - 1}  + \sin\left(\frac{\theta_n}{2}\right) \ket{\downarrow, n}\\
\ket{n, -} &\stackrel{\text{def}}{=} \cos\left(\frac{\theta_n}{2}\right) \ket{\downarrow, n}  - \cos\left(\frac{\theta_n}{2}\right) \ket{\uparrow, n - 1}
\end{align}
with:
\begin{equation}
\tan\left(\theta_n\right) = -\frac{4\sqrt{n}g}{\Delta\omega}
\end{equation}

To finish with the JC-model, we shall demonstrate one relevant case: the \textit{Rabi flopping} (or more explicitly the Rabi oscillations) when the detuning is null or can be assimilated as vanishing (i.e $\Delta\omega = 0$). Thereby, one starts with the two-level system as excited with an \textit{empty} cavity field:
\begin{equation}
\ket{\psi(0)} \stackrel{\text{def}}{=} \ket{\uparrow, n = 0} = \cos\left(\frac{\theta_{1}}{2}\right) \ket{1, +} - \sin\left(\frac{\theta_{1}}{2}\right) \ket{1, -}
\end{equation}
where we rewrite the initial state in terms of eigenstates.

Then, applying the spatial evolution operator, one finds (see Annexe ??)
\begin{align}
\ket{\psi(t)} &= e^{-\frac{i}{\hbar}E_{1,+}t} \cos\left(\frac{\theta_{1}}{2}\right) \ket{1, +} - e^{-\frac{i}{\hbar}E_{1,-}t} \sin\left(\frac{\theta_{1}}{2}\right) \ket{1, -}\\
&= \cos\left(\Omega t\right) \ket{\uparrow, 0} - i \sin\left(\Omega t\right) \ket{\downarrow, 1}
\end{align}
where we defined the Rabi frequency $\Omega = 2g$. Making the projection (i.e a measurment) along $\ket{\uparrow, 0}$ or $\ket{\downarrow, 1}$ and one ends up with the Rabi oscillations sketched on Fig ??.

(add figure!!)

As we can see on Fig ??, the probabilities of finding one photon with the atom in its ground state, while no photon with the atom in the excited state, oscillate in opposite phase.

Numerically, if one puts a small detuning (i.e $\omega_a$ is still about the same order of magnitude of $\omega_c$), one can numerically sketch Fig ?? where we see that the energy transfer is progressively discarded as we increase the detuning: the probabilities of inversing the intial state decreases.\footnote{Of course, it depends on the initial state. Here we choosed to work with the pair $\ket{\uparrow, 0}$ and $\ket{\downarrow, 1}$ but similar behaviors happen for other states.}

As we can notice, this model is mainly limited by its atomic level capability which is of number of two. Thereby, one would probably like to theoretically predict the behavior for many two-level systems (or equivalently several spins). Then, we shall introduce an extension of this model in the next section.

\section{Tavis-Cummings model}
\paragraph{}

In order to include more atoms, one needs to extend the Hilbert space involved into the JC-model. In fact, there are two ways of coupling more two-level systems, linked to the question: "Are the sub-systems distinguishable?". Indeed, here is the first \textit{naïve} idea to introduce $N$ atoms:
\begin{align}
\label{dist_sig_1}
\hat{\sigma}_i &\rightarrow \hat{\sigma}_i^1 \otimes \mathbb{1}^{2,...,N} + \mathbb{1}^{1} \otimes \hat{\sigma}_i^2 \otimes \mathbb{1}^{3,...,N} + ... + \mathbb{1}^{1,...,N-1} \otimes \hat{\sigma}_i^N\\
\label{dist_sig_2}
&\stackrel{\text{def}}{=} \sum_{j=1}^{N} \hat{\sigma}_i^j
\end{align}
where $i \in \left[x,y,z\right]$ and the upper indices indicate the Hilbert spaces involved into the operator owning them: $\mathbb{1}_{k,...,m}$ is the identity operator for the group of spaces from $k$ to $m$.\footnote{We intentionnaly split the tensor product in the transformation \eqref{dist_sig_1} for the sake of clarity even if the tensor product can be reversed. However, we drop the tensor notation in definition \eqref{dist_sig_2} for simplicity.}
As this transformation is made of linear combination of two-level system and as the unitary transformation in the previous section, involving commutator rules from the Pauli matrices, are still valid by independency of a system to another (i.e \eqref{sigma_commut} can be upper indexed for each Hilbert space), this leads to an equivalent hamiltonian of \eqref{HJC}:
\begin{equation}
\hbar\Delta\omega\,\hat{n} + \hbar g \sum_{j=1}^{N} \left(\hat{\sigma}_+^j \hat{a} + \hat{\sigma}_-^j \hat{a}^{\dag} \right)
\end{equation}
Thereby, this extended system is composed of $N+1$ independent sub-system with dimension scaling as $2^N \times N_{Fock}$ where $N_{Fock}$ is the space dimension of the cavity system. By \textit{independent}, we mean that each atom-like system is distinguishable from another. However, we do not have good reason to modelize our original experiment with independent atoms. Even worse, the superradiant effect is allowed by a collective ensemble, that is to say the atoms are indistinguishable and react as a whole multi-level system.\footnote{The second harmonic oscillator defined in \eqref{sec_bosonic_mw} could make sense but as the original argument in the JC-model, this bosonic structure doesn't allow a closed set of energies (i.e the atom group excitation could tend to infinity).} Indeed, R.H. Dicke, in its original paper [??] of coherent radiation process, states that the atom to atom distance (hence the gaz volume) must be much smaller than the wavelength of the surrounding electric field in order to reach an enhanced and coherent radiation. Nevertheless, in our experiment, the atomic cloud does not respect this condition for superradiance but as the atoms are enclosed into a cavity, this leads to collective interaction from the field to the cloud of atoms, hence indistinguishability.

Therefore, as the spins are assumed to be identical in \eqref{dist_sig_2}, one uses instead the collective spin operator:
\begin{equation}
\sum_{j=1}^{N} \hat{\sigma}_i^j \rightarrow \frac{\hbar}{2} \hat{S}_j
\end{equation}
where $\hat{S}_j$ follows the spin algebra similar to the Pauli matrices with, among other relations, the commutator:
\begin{equation}
{\displaystyle [\hat{S} _{j},\hat{S} _{k}]=i\hbar\varepsilon _{jkl}\,\hat{S} _{l}}
\end{equation}
Then, one obtains the following hamiltoninan for indistinguishable N two-level systems:
\begin{equation}
H_{TC} \stackrel{\text{def}}{=} \hbar\Delta\omega\,\hat{n} + g \left(\hat{S}_+ \hat{a} + \hat{S}_-\hat{a}^{\dag} \right)
\end{equation}
where the constant $g$ \textit{swallows} a factor of 2 (i.e $2g \rightarrow g$). Historically, this type of hamiltonian refers to the Tavis-Cummings (TC) model as it only includes a co-rotating term by the RWA (which is the actual interaction part of the TC-hamiltonian) then the TC-model keep the U(1) symmetry. However, R.H. Dicke proposes another hamiltonian involving a counter-rotating term of $\hat{S}_- \hat{a} + \hat{S}_+\hat{a}^{\dag}$ (without unitary transformation) which breaks the U(1) symmetry: we shall not utilize the Dicke model here because a posteriori (by simulation), the additional term is unnecessary.

This model may represent a group of N atom where each atom can be in its ground state or excited state, interacting with a radiation field. For practical reason, this system of two-level system is often called a \textit{gain medium} as models involving such systems can be utilized for LASER simulation where the the lasing beam is enhanced by population inversion.

By construction, if one choose a unique atom with $N=1$, the spin structure is quantized as:
\begin{equation}
s = \frac{1}{2} \quad; \quad m = \pm \frac{1}{2}
\end{equation}
which allows two pure states, similar to $\ket{\uparrow}$ and $\ket{\downarrow}$. Morevover, if one increases the number of atom to $N=2$, one get three pure states:
\begin{align*}
s = 1 \,;\, m = -1 \quad &\sim \quad \ket{\downarrow, \downarrow}\\
s = 1 \,;\, m = 1 \quad &\sim \quad \ket{\uparrow, \uparrow}\\
s = 1 \,;\, m = 0 \quad &\sim \quad \ket{\downarrow, \uparrow} \quad \textrm{or} \quad \ket{\uparrow, \downarrow}\\
\end{align*}
where the last case involves two well different states of the two distinguishable systems. However, our atoms are represented as a collective spin structure which means that they are indistinguishable leading to considerate those two different states as identical from an energy point of view. In that way, our system of collective spin system scales as $2 \times \frac{N}{2} + 1 = N + 1$ for $N$ two-level systems and the global system involving the field scales now as $(N+1) \times N_{Fock}$ which looses the exponential behavior from the distinguishable case: this is a great advantage from a simulation point of view.

In other words, one can create a global excitation state $\ket{s = N/2, m = N/2}$ where all the atoms are excited and, at the opposite, a global ground state $\ket{s = N/2, m = -N/2}$. However, for other values of $m$, one cannot \textit{say} or predict which atom or sub-group of atoms are excited: this leads to degeneracies determined by the binomial coefficient,
\begin{equation}
\textrm{Number of "equivalent state"} = \frac{N!}{N_{excited}!(N-N_{excited}!)} = \begin{pmatrix}
N\\
N_{excited}
\end{pmatrix} 	
\end{equation}
where $N_{excited}$ is the number of excited two-level syste, and the \textit{equivalent} term holds for a collective spin system point of view. It is well known that the maximum of the binomial coefficient is reached for $N_{excited} = \frac{N}{2}$ meaning that the maximum amount of degeneracies is reached when the gain medium is half-populated of excited entities.

Finally, we obtained a hamiltonian which looks very close to the JC-model and the natural question which now arises is: "How does one populate the gain medium of excitation? How the photons may leak oustside of the cavity?". For the first case, one may start with a state of the desired excited population. However, it exists another approach where our quantum system is included into a quantum \textit{bath}, allowing energy to leak in and out.\footnote{We do not go further into the spectrum caracterisation of $\hat{H}_{TC}$, even if it may be done, because the master equation shall complexify the exact solution at a point that we use another approach for the numerical simulation.}

\section{Open quantum systems and the master equation}
\paragraph{}

Firstly, we introduce the density operator in order to also treat probabilistic mixtures:
\begin{equation}
\label{def_dens_mat}
\rho \stackrel{\text{def}}{=} \sum_i p_i \ket{\psi_i}\bra{\psi_i}
\end{equation}
where $\left\lbrace \ket{\psi}, p_i \right\rbrace$ is a set of pure state associated to a probability. Equivalently, if we fix an arbitrary basis $\left\lbrace \ket{i} \right\rbrace$ of the Hilbert space, we can write:
\begin{equation}
\label{deftwo_dens_mat}
\rho = \sum_{i,j} \rho_{i,j} \ket{i}\bra{j}
\end{equation}
where $\rho_{i,j}$ are the matrix coefficient of $\rho$ in the the given basis. It can be shown that a density matrix fulfill three essential conditions which are equivalent in regard of \eqref{def_dens_mat}:
\begin{itemize}
	\item $\rho$ is positive semi-definite: $\bra{v} \rho \ket{v} \geqslant 0, \quad \forall \ket{v}$
	\item $\rho$ is hermitian: $\rho = \rho^\dagger$
	\item $\rho$ is trace one: $\sum_i p_i = \sum_i \rho_{i, i} = 1$
\end{itemize}

As a ket state obeys to Schrodinger's equation, one can derive a similar equation of evolution for a density matrix, called \textit{Liouville - von Neumann} equation. Indeed, one may consider the two following equations:
\begin{equation}
i\hbar\partial _t\ket{\phi} = \hat{H}\ket{\phi} \Leftrightarrow -i\hbar\partial _t\bra{\phi} = \bra{\phi}\hat{H}
\end{equation}
where $\ket{\phi}$ is any solution to the Schrodinger equation. Then coupling those to \eqref{def_dens_mat} one shall find:
\begin{equation}
\label{vonneuman}
i\hbar\dot{\rho} = \left[ \hat{H}, \rho \right] \Leftrightarrow \dot{\rho} = -\frac{i}{\hbar} \left[ \hat{H}, \rho \right]
\end{equation}
One can notice that this equation relies on the Schrodinger point of view, where the states evolves in time whereas the operators are static. At the opposite, the Heinsenberg picture gives:
\begin{equation}
\dot{\hat{X}} = \frac{i}{\hbar} \left[ \hat{H}, \hat{X} \right]
\end{equation}
where $\hat{X}$ is any operator (not necessecarily an observable or hermitian).\footnote{This brutal change of picture shall be crucial for the section introducing $g^1$ and $g^2$ simulation with the cumulant expansion technique.}

At this point, we are able to simulate the evolution of the closed quantum TC-model for any initial state. It turns out that our experiment involves several \textit{leaks} (in and out) in term of global energy: they are three in number:
\begin{itemize}
	\item Cavity leak: as mentionned in section 1.1, the cavity purpose is to release a part of the electric field (at the cost of the linewidth broadened) in order to actually collect the radiation. In other words, some photons are transmitted through one of the mirror: this is a global energy loss in our TC system.
	\item Gain medium leak: counter-intuitively, the atoms (or dipole systems) may incoherently release a photon with frequency very different to the actual cavity resonances. Those photons does not couple to the surrounding electric field and are lost: this effect is another global energy loss and is called \textit{spontaneous decay into free space}.
	\item Gain medium repump: as the expriments works on a \textit{quasi}-continous radiation, even starting with excited atoms (which is not the case), we need to add some energy in order to compensate the phase coherent decay of our atoms which produce the actual radiation (through the cavity leak). This is a global energy gain in the system.
\end{itemize}

Therefore, we introduce a quantum \textit{bath} system which represent the environment of our TC quantum system. The total hamiltonian reads\footnote{For simplicity, we drop the tensor product but it is important to keep in mind that the total hamiltonian lives into an Hilbert space with higher dimension than the TC system.}
\begin{equation}
\hat{H}_{total} = \hat{H}_{TC} + \hat{H}_{bath} + \hat{H}_{TC-bath}
\end{equation}
Then, one chooses the interaction picture where the evolution is set by the interaction hamiltonian $\hat{H}_{TC-bath}$ between the bath and our system. One starts with a bath and our system without cross correlation. Afterward, the time evolution of the density matrix of the total system can be written in term of an infinite iterative equation: one uses the \textit{Born} approximation stating that the bath-TC interaction coupling is weak compared to the size of the bath, allowing to \textit{cut} the inifinte serie as the bath evolution is independent of the system evolution. Then, one makes a last assomption that the bath has a \textit{short memory} meaning that the correlations are not significant for long time intervals if the bath is subject to fast dynamics: this is the \textit{Markov} approximation.

At the end of the day, one obtains the open quantum system equation, often called the \textit{master equation}:
\begin{equation}
\dot{\rho} = -\frac{i}{\hbar} \left[ \hat{H}, \rho \right] + \sum_j \gamma_j \left( \hat{L}_j \rho \hat{L}_j^\dagger - \frac{1}{2} \left\lbrace \hat{L}_j^\dagger \hat{L}_j, \rho \right\rbrace \right)
\end{equation}
where $j$ indexes the different \textit{leak} operators $\hat{L}_j$, often called \textit{jump} operators or more simply \textit{lindblad} operators. Also, $\gamma_j$ are the associated \textit{damping} rate (even if the operator's purpose may be to add energy) and the curly brackets are the anti-commutator relation.
Equivalently for the Heisenberg picture, on finds:
\begin{equation}
\label{master_eq_heis}
\dot{\hat{X}} = \frac{i}{\hbar} \left[ \hat{H}, \hat{X} \right] + \sum_j \gamma_j \left( \hat{L}_j^\dagger \hat{X} \hat{L}_j - \frac{1}{2} \left\lbrace \hat{L}_j^\dagger \hat{L}_j, \hat{X} \right\rbrace \right)
\end{equation}
where one may notice the sign difference in front of the commutator and the opposite dagger symbol on the lindblad operator of the first term of the sum.
In our case, we get three lindblad operators, representing the various \textit{leaks} of the TC quantum system:
\begin{itemize}
	\item The cavity leak or \textit{cavity decay} operates at a rate $\kappa$. The associated lindblad operator is the destruction operator of the cavity field $\hat{a}$: this ladder operator removes energy from the harmonic oscillator.
	\item The spontaneous decay into free space operates at a rate $\gamma$. The associated lindblad operator is the collective spin ladder operator $\hat{S}_-$ which \textit{collectively} removes energy from the atomic system.
	\item The repump operates at a rate $\nu$ and is associated to the lindblad operator $\hat{S}_+$: we assume that an external laser \textit{feeds} collectively the ensemble of two-level system, which has for effect to add energy into the TC quantum system.
\end{itemize}

To summarize, the density matrix evolution responds to the following first order differential equation:
\begin{align}
\label{rho_master_eq}
\begin{split}
\dot{\rho} = &\left[ \rho \, , \, i\Delta\omega\,\hat{n} + \frac{i}{\hbar} g \left(\hat{S}_+ \hat{a} + \hat{S}_-\hat{a}^{\dag} \right)\right]\\
&+ \kappa \left( \hat{a} \rho \hat{a}^\dagger - \frac{1}{2} \left\lbrace \hat{a}^\dagger \hat{a}, \rho \right\rbrace \right)\\
&+ \gamma \left( \hat{S}_- \rho \hat{S}_+ - \frac{1}{2} \left\lbrace \hat{S}_+ \hat{S}_-, \rho \right\rbrace \right)\\
&+ \nu \left( \hat{S}_+ \rho \hat{S}_- - \frac{1}{2} \left\lbrace \hat{S}_- \hat{S}_+, \rho \right\rbrace \right)
\end{split}
\end{align}
where with have taken $\hat{H}_{TC}$ as the hamiltonian. There is a similar equation (close to a sign and dagger operators) for any operator $\hat{X}$. This differential equation is a system of linear differential equation in a sense that each time derivated term of the density matrix is dependent of linear terms of the density matrix. In other words:
\begin{equation}
\dot{\rho_{i,j}} = \sum_{k,l} \alpha_{k,l} \rho_{k,l}
\end{equation}
where $\rho_{i,j}$ are the density matrix components with indices $(i,j)$ $\alpha_{k,l}$ are fixed complex coefficent dependent on operator values and constants. 

Thereby, this system is numerically solvable with standard integration methods as the Runge-Kutta approach.\footnote{Note that the Runge-Kutta method is not restricted to linear systems as, by definition, this approach treats any function $f$ where $\dot{y} = f(y, t)$ and $y$ can be any variable of any vector space: $y \in \mathbb{R}, \mathbb{R}^2, \mathbb{R}^3, ..., \mathbb{C}, \mathbb{C}^2, \mathbb{C}^3, ...$ for examples.} As one could think, if the system is linear, it should be diagonalizable hence exactly solvable by exponentiation. However, this approach is not possible in the form of \eqref{rho_master_eq} as the equation is treating the density operator as, obsviously, a matrix. 

Nevertheless, one may introduce a new concept called the \textit{linearization} of the density operator. In fact, the density matrix lies in the Hilbert space $\mathscr{H}_{TC} = \mathscr{H}_{cav} \otimes \mathscr{H}_{atoms}$ and one may transform this matrix into a vector lying in the new space $\mathscr{H}_{TC} \otimes \mathscr{H}_{TC}$, which is often called the \textit{Fock-Liouville space}. In this way, \eqref{deftwo_dens_mat} becomes:
\begin{equation}
\rho = \sum_{i,j} \rho_{i,j} \ket{i}\bra{j} \rightarrow \sum_{i,j} \rho_{i,j} \ket{i} \otimes \ket{j} = \begin{pmatrix}
\rho_{0,0}\\
\rho_{0,1}\\
\vdots\\
\rho_{n-1,n-1}
\end{pmatrix}
\stackrel{\text{def}}{=} \kket{\rho}
\end{equation}
where $n$ is the dimension of $\mathscr{H}_{TC}$. Then, the von-Neumann equation \eqref{vonneuman} transforms as:
\begin{equation}
\dot{\rho} = -\frac{i}{\hbar}\left( \hat{H}\rho - \rho\hat{H} \right) \rightarrow \kket{\dot{\rho}} = -\frac{i}{\hbar} \mathcal{H}\kket{\rho}
\end{equation}
where $\mathcal{H}$ is a superoperator defined as $\mathcal{H}\kket{\cdot} \rightarrow \left[ \hat{H}, \cdot \right]$.\footnote{This is not a definition symbol because the left side does not lie in the same space as the right side: $\mathcal{H}$ belongs to the \textit{superspace} $\mathscr{H}_{TC} \otimes \mathscr{H}_{TC}$ whereas the commutator lies in $\mathscr{H}_{TC}$ only.} Similarly, one may define the lindblad superoperator:
\begin{equation}
\mathcal{D}[\hat{L}_j] \kket{\rho} \rightarrow \hat{L}_j \rho \hat{L}_j^\dagger - \frac{1}{2} \left\lbrace \hat{L}_j^\dagger \hat{L}_j, \rho \right\rbrace
\end{equation}
and the master equation becomes:
\begin{align}
\begin{split}
\kket{\dot{\rho}} &= -\frac{i}{\hbar} \mathcal{H}\kket{\rho} + \kappa \mathcal{D}[\hat{a}] \kket{\rho} + \gamma \mathcal{D}[\hat{S}_-] \kket{\rho} + \nu \mathcal{D}[\hat{S}_+] \kket{\rho}\\
&= \left(-\frac{i}{\hbar} \mathcal{H} + \kappa \mathcal{D}[\hat{a}] + \gamma \mathcal{D}[\hat{S}_-] + \nu \mathcal{D}[\hat{S}_+]\right)\kket{\rho} \\
&= \mathcal{L}\kket{\rho}
\end{split}
\end{align}
where we defined the Liouvillian superoperator $\mathcal{L}$ from the second line of the equation. From that, it is possible to calculate the eigenvalues and eigenvectors in order to find the exact values of $\kket{\rho}$ at any time $t$.\footnote{Note that as the Liouvillian superoperator is not hermitian by construction, the right and left eigenvectors are associated to different eigenvalues. See [??] for more details.}

However, the first limitation of this method is the size of the system. Indeed, as $\mathscr{H}_{TC}$ scales according to $(N+1) \times N_{Fock}$ then the Fock-Liouville space scales as the square:
\begin{equation}
\textrm{dim}\left(\mathscr{H}_{TC} \otimes \mathscr{H}_{TC}\right) = \left((N+1) \times N_{Fock}\right)^2
\end{equation}
In order to hold the decay of the atoms, the Fock space associated to the cavity field must be at least the same dimension as the number of two-level systems.\footnote{In practice, we take twice the size for \textit{security} and a double check of the photon number, after computation, asserts that we are not overflowing the Fock space.} Then, for $N$ dipoles as a gain medium:
\begin{equation}
\textrm{dim}\left(\mathscr{H}_{TC} \otimes \mathscr{H}_{TC}\right) \sim N^4
\end{equation}
Thereby, the number of components for the vector $\kket{\rho}$ scales according to the same rule. Moreover, the number of components inside the \textit{super}-matrix representing the Liouville superoperator scales as the square of it, namely as $N^8$. For instance, let's say that we want to numerically simulate our model with one hundred atoms: the super-matrix owns $10^{16}$ components. As each component is a complex number represented by two floats of 32-bit each (in the low precision case): 8 byte per component. At the end of the day, we need approximately $80,000$ TB only to store the Liouvilian superoperator\footnote{1TB = 1000 GB which is somehow a common hard-drive capacity for the family computers on the current tech-market (2024).}. Ideally, we would like to simulate a couple of millions of atoms.

Unfortunately, the first method of solving, involving the RK intergation, suffers the same problem for many particles: as we stay in the original Hilbert space $\mathscr{H}_{TC}$, the power scale is less important but many atoms simulation is still unreachable for more than a few hundreds of atoms. Even worse, this solution is not exact, in a sense that we get the solution for a finite time interval where the computation time is dependent on it!

This case is a good example of the classical computer limitation and this sort of problem is part of the reason of building a quantum computer/simulator. Indeed, one could make use of the parallelism behavior of the qubit in order to simulate many cross interaction at the same time. However, those kind of projects are not yet achieved and we have to find a \textit{smart} solution, in a sense that we are ready to lose a bit of precision in exchange of computation power and memory space. In fact, all the crossed terms essentially represent the multiple interaction holded by each atom. Secondly, the question we have to ask is: "what mesure do we want from the simulation?". As we shall see in later section, our interested correlation function are, roughly, the expectation values of operators accross the time. In other words, we absolutely do not care about the behavior of individual terms. So, what happens if one plugs directly the excpectation value on the "Heisenberg version" of the master equation \eqref{master_eq_heis}? This is the subject of the next section.

\section{Cumulant expansion method}
\paragraph{}

Firstly, even if we go into more details in chapter ?? about their signification, we have to recall what are the first and second order correlation function in term of quantum operators in order to visualize which sort of values we need to extract from the master equation.

Thereby, in the case of a non-stationary electric field, one can define the first order correlation function as:
\begin{equation}
{\displaystyle g ^{1}(t_{1},t_{2})\stackrel{\text{def}}{=}{\frac {\left\langle E^{*}(t_{1})E(t_{2})\right\rangle }{\sqrt{\left\langle \left|E(t_{1})\right|^{2}\right\rangle \left\langle \left|E(t_{2})\right|^{2}\right\rangle }}}}
\end{equation}
where $E(t) \in \mathbb{C}$ is the phasor representation of the electric field and the mean symbol $\left\langle \cdot \right\rangle$ is an ensemble average over a set of electric signal. Note that we also make the assumption that the correlation measurement is done at $r_1 = r_2 = 0$ for both detectors of the electric field.

In turns out that any eletric field can be quantized  with the help of an artificial \textit{quantization box} of volume $V$ and the associated formulas are:
\begin{equation}
{\displaystyle {\hat {E}}^{+}=i\sum \limits _{\vv {k} ,\lambda }{\sqrt {\frac {\hbar \omega _{k}}{2\epsilon _{0}V}}}{\hat {a}}_{\vv {k} ,\lambda }e^{i\vv {k} .\vv {r} }\vv {e} _{\vv {k} ,\lambda }} \quad \quad {\displaystyle {\hat {E}}^{-}=-i\sum \limits _{\vv {k} ,\lambda }{\sqrt {\frac {\hbar \omega _{k}}{2\epsilon _{0}V}}}{\hat {a}}^\dagger_{\vv {k} ,\lambda }e^{-i\vv {k} .\vv {r} }\vv {e}^* _{\vv {k} ,\lambda }}
\end{equation}
where ${\displaystyle \omega _{k}}$ is the mode frequency associated to the polarization vector ${\displaystyle \vv {k} }$, 
${\displaystyle \vv {e} _{\vv {k} ,\lambda }} \in \mathbb{C}^3$ is the unit vector perpendicular to 
${\displaystyle \vv {k} }$, with 
${\displaystyle \lambda }$ signifying one of the two vectors that are perpendicular to the polarization vector. Now, making the assumption that the electric field is composed of one frequency (i.e a unique mode of the \textit{fake}-cavity) and replacing the electric field phasor components by their quantum operator counterparts, one finds the quantum equivalent of the first order correlation function:
\begin{equation}
g^1(t_1, t_2) = \frac{\left\langle \hat{a}^\dagger(t_1)\hat{a}(t_2) \right\rangle}{\sqrt{\left\langle \hat{a}^\dagger(t_1)\hat{a}(t_1) \right\rangle \left\langle \hat{a}^\dagger(t_2)\hat{a}(t_2) \right\rangle}}
\end{equation}
where we may notice that the denominator terms are function of the mean photon number $\hat{n}$ at time $t_1$ and $t_2$. Moreover, we considered the time evolution of the electric field as the time evolution of the operators, in other words, the Heisenberg picture. This consideration comes from the fact that the numerator is a mean value of two operators evaluated at a different time each. Indeed, we define the mean value of any operator $\hat{X}$ as the quantum measurement of $\hat{X}$ over a pure state $\ket{\psi}$ or a density matrix $\rho$:\footnote{Equation \eqref{quantum_meas} is directly derivated from the second postulate (\textit{measurement postulate}) of the Quantum Mechanic Theory.}
\begin{equation}
\label{quantum_meas}
\left\langle \hat{X} \right\rangle_{\psi \, or \, \rho} = \bra{\psi}\hat{X}\ket{\psi} \quad or \quad \Tr \left[ \rho \hat{X} \right]
\end{equation}
Which leads, for the time evolution of the mean value, to the two famous pictures (considering a density matrix as the measured state):
\begin{align}
\begin{split}
\textrm{Schrödinger picture:} \quad\quad \left\langle \hat{X} \right\rangle_{\rho} (t) = \Tr \left[ \rho(t)\cdot \hat{X} \right]\\
\textrm{Heisenberg picture:} \quad\quad \left\langle \hat{X} \right\rangle_{\rho} (t) = \Tr \left[ \rho\cdot \hat{X}(t) \right]\\
\end{split}
\end{align}
If we set $\hat{X}(t_1,t_2) = \hat{Y}(t_1)\hat{Z}(t_2)$, it becomes obvious that the Heinsberg picture is appropriate:
\begin{equation}
\left\langle \hat{X} \right\rangle _{\rho} (t_1, t_2) = \Tr \left[ \rho \cdot \hat{Y}(t_1) \cdot \hat{Z}(t_2)\right]
\end{equation} 
In other words, we are looking for the time evolution of $\hat{a}^\dagger$ and $\hat{a}$ but not the time evolution of the initial state. By the way, those previous equations shows that the quantum $g^1$ is dependent on the choice of the initial state.

It is important to note that $g^1$ is by definition a 2D map\footnote{Only in its non-stationary form.}. As we are going to run numerical simulations through it, we can consider $t_2$ as a fixed value and compute the time evolution of $g^1$ according to $t_1$:
\begin{equation}
\label{quantum_g1_1D_map}
g^1(t_1)_{t_2} = \frac{\left\langle \hat{a}^\dagger(t_1)\hat{a}_{t_2} \right\rangle}{\sqrt{\left\langle \hat{n}(t_1) \right\rangle \left\langle \hat{n}_{t_2} \right\rangle}}
\end{equation}
which is a 1D map (i.e a function), then repeat the process for every $t_2$ of the targeted time interval.

Moreover, in the stationary case, the distribution of the the electric signal is independent of time and one may find that $g^1$ is only dependent on the time difference $t_1 - t_2 \stackrel{\text{def}}{=} \tau$:
\begin{equation}
g^1(\tau)_{stationary} = \frac{\left\langle \hat{a}^\dagger(t_2 + \tau)\hat{a}(t_2) \right\rangle}{\sqrt{\left\langle \hat{n}(t_2 + \tau) \right\rangle \left\langle \hat{n}(t_2) \right\rangle}}=\frac{\left\langle \hat{a}^\dagger(\tau)\hat{a}(0) \right\rangle}{\sqrt{\left\langle \hat{n}(\tau) \right\rangle \left\langle \hat{n}(0) \right\rangle}}
\end{equation}
where we set $t_2 = 0$ as the process is considered as stationary, hence, independent on the reference time. Note the similarities with the non-stationary case \eqref{quantum_g1_1D_map} from a computational point of view: the reference time $t_2$ is just a question of initial value of the operators $\hat{a}$ and $\hat{n}$.

Similarly, for the classical second order correlation fonction, one defines:
\begin{equation}
{\displaystyle g ^{2}(t_{1},t_{2})\stackrel{\text{def}}{=}{\frac {\left\langle E^{*}(t_{2})E^{*}(t_{1})E(t_{1})E(t_{2})\right\rangle }{\left\langle \left|E(t_{1})\right|^{2}\right\rangle \left\langle \left|E(t_{2})\right|^{2}\right\rangle}}}
\end{equation}
Then, the quantum equivalent reads as:
\begin{equation}
{\displaystyle g ^{2}(t_1, t_2)={\frac {\left\langle \hat{a}^\dagger(t_2)\hat{a}^\dagger(t_1)\hat{a}(t_1)\hat{a}(t_2)\right\rangle }{\left\langle \hat{n}(t_1) \right\rangle \left\langle \hat{n}(t_2) \right\rangle}}}
\end{equation}
As before, the stationary assumption allows us to write:
\begin{equation}
{\displaystyle g ^{2}(\tau)={\frac {\left\langle \hat{a}^\dagger(0)\hat{a}^\dagger(\tau)\hat{a}(\tau)\hat{a}(0)\right\rangle }{\left\langle \hat{n}(\tau) \right\rangle \left\langle \hat{n}(0) \right\rangle}}}
\end{equation}
\footnote{It is possible to define $t_2 - t_1 \stackrel{\text{def}}{=} \tau$. This time reverse step does not affect the function itself as $g^2(\tau) = g^2(-\tau)$ for a stationary process. The same property hold for $g^1$.}.

At the end of day, the desired quantities are complex values dependent on operator evolution. That is to say, we actually want the quantum measurement of the ladder and photon number operators. Then, let's start with the value $\left\langle\hat{a}^\dagger\right\rangle$ from the differential equation:
\begin{align}
\begin{split}
\frac{d}{dt}\hat{a}^\dagger = &\quad\frac{i}{\hbar}\left[ \hat{a}^\dagger \, , \,\hat{H}_{TC} \right]\\
&+ \kappa \left( \hat{a} \hat{a}^\dagger \hat{a}^\dagger - \frac{1}{2} \hat{a}^\dagger \hat{a} \hat{a}^\dagger - \frac{1}{2} \hat{a}^\dagger \hat{a}^\dagger \hat{a} \right)\\
&+ \gamma \left( \hat{S}_- \hat{a}^\dagger \hat{S}_+ - \frac{1}{2} \hat{S}_+ \hat{S}_- \hat{a}^\dagger - \frac{1}{2} \hat{a}^\dagger \hat{S}_+ \hat{S}_- \right)\\
&+ \nu \left( \hat{S}_+ \hat{a}^\dagger \hat{S}_- - \frac{1}{2} \hat{S}_- \hat{S}_+ \hat{a}^\dagger - \frac{1}{2} \hat{a}^\dagger \hat{S}_- \hat{S}_+ \right)
\end{split}
\end{align}
which is the \textit{Heisenberg} equivalent of \eqref{rho_master_eq}.\footnote{We intentionally omit the artcifial order of the operators that we made earlier for the implicit representation of the tensor structure: no ordering allows us to highlight the lindblad operators.} One uses the standard commutation relations, remembering that the collective spin operator does not lie into the same space as the cavity ladder operators then one obtains\footnote{See details in Annexe ??}:
\begin{equation}
\label{ad_pure}
\frac{d}{dt}\hat{a}^\dagger = \left(i\Delta\omega - \frac{\kappa}{2} \right) \hat{a}^\dagger + \frac{ig}{\hbar} \hat{S}_+
\end{equation}
Making measurement according to a state $\rho$ and knowing that a projection is a linear operation on a time derivative, one gets:
\begin{equation}
\label{ad_mean_field}
\frac{d}{dt}\left\langle\hat{a}^\dagger\right\rangle = \left(i\Delta\omega - \frac{\kappa}{2} \right) \left\langle\hat{a}^\dagger\right\rangle + \frac{ig}{\hbar} \left\langle\hat{S}_+\right\rangle
\end{equation}
which is again a differential equation involving but involving only complex (or real) numbers: we have lost all the cross interaction information contained inside the operator and reduced it to the mean value of the operators. However, this first order differential equation is of two variable instead of one as the master equation with the variable $\rho$. Indeed, $\left\langle\hat{S}_+\right\rangle$ is also time dependent and one needs its time evolution in order to solve the equation: in fact, we are actually treating a system of equations and are now looking for the second member. Then, we can reengage the process with the operator $\hat{S}_+$ instead and the differential equation is this time:
\begin{equation}
\frac{d}{dt}\left\langle\hat{S}_+\right\rangle = -2ig\left\langle\hat{S}_+ \hat{a}^\dagger\right\rangle + \hbar (\nu - \gamma)\left\langle \hat{S}_z \hat{S}_+\right\rangle - \nu \hbar ^2 \left\langle\hat{S}_+\right\rangle
\end{equation}
Unfortunately, this new equation leads to new variables, namely: $\left\langle\hat{S}_+ \hat{a}^\dagger\right\rangle$ and $\left\langle \hat{S}_z \hat{S}_+\right\rangle$. Moreover, the mean value or cross-correlation between two operators (or even for two random variable from a classical point of view) is not equal to the multiplication of the individual correlations: 
\begin{equation}
\left\langle \hat{X}\hat{Y} \right\rangle \neq \left\langle \hat{X} \right\rangle \left\langle \hat{Y} \right\rangle
\end{equation} 
Therefore, it makes sense to write:
\begin{equation}
\left\langle \hat{X}\hat{Y} \right\rangle = \left\langle \hat{X} \right\rangle \left\langle \hat{Y} \right\rangle
\end{equation} 
only if we assume that $\hat{X}$ and $\hat{Y}$ are independent in term of probability representation. In that case, one loses all the quantum interaction happening in the correlated variables: this approximation is named \textit{mean field approximation}.

If one applies this approximation, one shall obtain:
\begin{equation}
\label{sp_mean_field}
\frac{d}{dt}\left\langle\hat{S}_+\right\rangle = -2ig\left\langle\hat{S}_+ \right\rangle\left\langle\hat{a}^\dagger\right\rangle + \hbar (\nu - \gamma)\left\langle \hat{S}_z \right\rangle\left\langle\hat{S}_+\right\rangle - \nu \hbar ^2 \left\langle\hat{S}_+\right\rangle
\end{equation}
Now the only missing variable equation evolution is $\left\langle \hat{S}_z \right\rangle$. Then we repeat the process again and we find two more equations.
\begin{equation}
\label{sz_mean_field}
\frac{d}{dt}\left\langle\hat{S}_z\right\rangle = -ig\left\langle\hat{S}_+ \right\rangle\left\langle\hat{a}\right\rangle + ig\left\langle\hat{S}_- \right\rangle\left\langle\hat{a}^\dagger\right\rangle + \hbar (\gamma - \nu)\left\langle \hat{S}_- \right\rangle\left\langle\hat{S}_+\right\rangle - 2\nu \hbar ^2 \left\langle\hat{S}_z\right\rangle
\end{equation}
One can be tented to develop two more variables which would be $\left\langle\hat{S}_- \right\rangle$ and $\left\langle\hat{a}\right\rangle$. However, those two operators are the conjugate transpose of $\hat{S}_+$ and $\hat{a}^\dagger$ respectively and their quantum measurement is just complex conjugate:
\begin{equation}
\left\langle\hat{S}_- \right\rangle = \left\langle\hat{S}_+ \right\rangle^* \quad\quad \left\langle\hat{a}\right\rangle = \left\langle\hat{a}^\dagger\right\rangle^*
\end{equation}
Therefore, the three differential equations \eqref{ad_mean_field}, \eqref{sp_mean_field} and \eqref{sz_mean_field} form a complete system of equation, hence, can be solved taking the initial values as:
\begin{equation}
\left\langle \hat{a}^\dagger \right\rangle (t=0) = \Tr\left[ \rho \hat{a}^\dagger_0 \right]
\end{equation}
where $\rho$ is the initial density matrix of the system and $\hat{a}^\dagger_0$ is the common constructor operator\footnote{Note that a $t=0$, quantum measurements according to the Schrödinger or Heisenberg picture are equivalent.}. One may say that this system of equation is a \textit{closed} form in a sense that, with the mean field approximation, if one chooses any of the five operators $\hat{a}^\dagger$,$\hat{a}$, $\hat{S}_+$, $\hat{S}_-$ or $\hat{S}_z$ at the start, then the final set of differential would be exactly the same as \eqref{ad_mean_field}, \eqref{sp_mean_field} and \eqref{sz_mean_field} (taking into account the complex conjugated equations).

Now, we have to remember that, in addition of retrieving the quantum correlation lost with the mean field approximation (i.e a first order approximation), our goal is to get the evolution of correlation functions involving several operators. In fact, it is clear that if we develop a differential equation with $\left\langle\hat{S}_+ \hat{a}^\dagger\right\rangle$ for example, we shall get correlation variables involving three or more operators. Reapting the process will certainly give an infinity amount of differential equations. In other words, we have to \textit{break the loop} with a certain order of approximation. In this way, one may invoke the definition of the \textit{joint cumulant}:
\begin{equation}
\left\langle\hat{X}_1\hat{X}_2...\hat{X}_n\right\rangle_c \stackrel{\text{def}}{=} \sum_{p \in P(\mathcal{I})} (\vert p \vert - 1)!(-1)^{\vert p \vert -1} \prod_{B \in p} \left\langle \prod_{i \in B}\hat{X}_i\right\rangle
\end{equation}
where $\mathcal{I} = \left\rbrace 1,2, ..., n \right\rbrace$, $P(\mathcal{I})$ is the set of all partition of $\mathcal{I}$, $\vert p \vert$ is the length of the partition and B is successively each element of the partition. It is possible to prove (ref ??) that the joint cumulant is null if any operator $\hat{X}_i$ is independent of all the others (in term of probabilities). Then, the main approximation is to assume that, at a certain number of operator $m$ inside the cumulant, at least one of the operator among them is independent of the others. This implies $\left\langle\hat{X}_1\hat{X}_2...\hat{X}_m\right\rangle_c = 0$ and one may write:
\begin{equation}
\left\langle\hat{X}_1\hat{X}_2...\hat{X}_m\right\rangle = \sum_{p \in P(\mathcal{I})/\mathcal{I}} (\vert p \vert - 1)!(-1)^{\vert p \vert -1} \prod_{B \in p} \left\langle \prod_{i \in B}\hat{X}_i\right\rangle
\end{equation}
where $\mathcal{I} = \left\lbrace 1,2, ..., n \right\rbrace$ and $P(\mathcal{I})/\mathcal{I}$ is the set of all the partitions of $\mathcal{I}$ without $\mathcal{I}$ itslef. From that, it is obvious that the mean field approximation is condidering  this formula  with $m=2$. Then, for $m=3$:
\begin{equation}
\left\langle\hat{X}_1\hat{X}_2\hat{X}_3\right\rangle = \left\langle\hat{X}_1\hat{X}_2\right\rangle\left\langle\hat{X}_3\right\rangle + \left\langle\hat{X}_1\hat{X}_3\right\rangle\left\langle\hat{X}_2\right\rangle + \left\langle\hat{X}_2\hat{X}_3\right\rangle\left\langle\hat{X}_1\right\rangle - 2\left\langle\hat{X}_1\right\rangle\left\langle\hat{X}_2\right\rangle\left\langle\hat{X}_3\right\rangle
\end{equation}
and so on for $m>3$. This approximation is named the \textit{cumulant expansion method}.

At the end of day, the algorithmic approach is choosing an order $m$ where, if one finds a correlation variable with $m$ or more operators inside of the correlation brackets when developing the set of equations, one applies the cumulant expansion in order to transform a correlation variable of $m$ operators into several correlation variables of $m-1$ operators. In other words, $m$ is the amount of operators where one \textit{breaks the loop}. Finally, one may choose any order of approximation knowing that greater is the order (i.e, more operator we have inside the correlation brackets), more quantum correlations one takes into account (i.e more precision in the simulation) \textit{but} more equations one has to treat and more computational power is needed. The question is then to find a good compromise.

Nevertheless, at any order of the expansion one can go, the time evolution of the correlation variable involve the time evolution of all the operators inside of it at the same time reference. That is to say:
\begin{equation}
\left\langle\hat{X}_1\hat{X}_2\right\rangle (t) = \left\langle\hat{X}_1(t)\hat{X}_2(t)\right\rangle
\end{equation}
for instance. In other words, one cannot access the $g^1$ and $g^2$ values directly from this method as those two correlation invlove different time evolution of the operators. However, one may see from \eqref{quantum_g1_1D_map} that the desired differential equation needed for $g^1$ before making the quantum measurment (i.e before applying $\left\langle \cdot \right\rangle$) reads:
\begin{equation}
\frac{d}{dt_1} \left(\hat{a}^\dagger(t_1)\hat{a}_{t_2}\right) = \frac{d}{dt_1} \left(\hat{a}^\dagger(t_1)\right)\hat{a}_{t_2}
\end{equation}
where $\hat{a}_{t_2}$ is treated as a constant compared to $t_1$. We can see that the right term of the previous equation calls the already derivated formula \eqref{ad_pure} of $\hat{a}^\dagger$, which is of the form:
\begin{equation}
\frac{d}{dt_1} \hat{a}^\dagger(t_1) = f(\hat{a}^\dagger(t_1)) 
\end{equation}
where $f$ is basically the heisenberg version of the master equation. Then multiplying by a tme constant operator (compared to $t_1$), namely $\hat{a}_{t_2}$ \footnote{We make this choice of $\hat{a}_{t_2}$ in order to fit the $g^1$ notation but it is important to keep in mind that it could be any constant operator.}, one obtains:
\begin{equation}
\frac{d}{dt_1} \left(\hat{a}^\dagger(t_1)\right) \hat{a}_{t_2} = f(\hat{a}^\dagger(t_1)) \hat{a}_{t_2}
\end{equation}
which, in the case of \eqref{ad_pure}, reads as:
\begin{equation}
\frac{d}{dt_1}\left(\hat{a}^\dagger(t_1)\right)\hat{a}_{t_2} = \left(i\Delta\omega - \frac{\kappa}{2} \right) \hat{a}^\dagger(t_1)\hat{a}_{t_2} + \frac{ig}{\hbar} \hat{S}_+(t_1)\hat{a}_{t_2}
\end{equation}
Now, one can make a quantum measurement and gets:
\begin{equation}
\label{g1_explicit_cumu}
\frac{d}{dt_1}\left\langle\hat{a}^\dagger(t_1)\hat{a}_{t_2}\right\rangle = \left(i\Delta\omega - \frac{\kappa}{2} \right) \left\langle\hat{a}^\dagger(t_1)\hat{a}_{t_2}\right\rangle + \frac{ig}{\hbar} \left\langle\hat{S}_+(t_1)\hat{a}_{t_2}\right\rangle
\end{equation}
Of course, this \textit{multiplication followed by quantum measurement} must be applied to the whole set of differential equation in order to \textit{update} all the correlation variables: before obtaining \eqref{g1_explicit_cumu}, one derived the closed system of equation containing $\left\langle\hat{S}_+(t_1)\right\rangle$ but not $\left\langle\hat{S}_+(t_1)\hat{a}_{t_2}\right\rangle$\footnote{Algorithmically speaking, the set is first derived without applying the brackets (i.e quantum measurement), then the multiplication and brackets are applied.}.

The initial value of \eqref{g1_explicit_cumu} is expressed as:
\begin{equation}
\left\langle\hat{a}^\dagger(t_1)\hat{a}_{t_2}\right\rangle (t_1=0) = \left\langle\hat{a}^\dagger_0\hat{a}_{t_2}\right\rangle
\end{equation}
However, we do not dispose to this information as we only know the initial operator values $\hat{a}^\dagger_0$ and $\hat{a}_0$ but not the time evolution of $\hat{a}_{t_2}$. Nevertheless, if we derive a set of equation to a certain order allowing the access to the correlation variable $\left\langle\hat{a}^\dagger(t)\hat{a}(t)\right\rangle$, then we can get any intial value of \eqref{g1_explicit_cumu} for $t_1=t_2$: solving the system of differential equation leads to solution with $t_1\geqslant t_2$ which represents the lower-half of the 2D map accoring to the diagonal $t_1=t_2$ as on Fig ??.

This initial value problem only stands for non-stationary processes. Indeed, for a stationary process, we firstly have to numerically compute a time interval long enough to reach the steady-state of the correlation variables. Then, as stated in the begining of this section, $g^1$ for a stationary process is dependent on the time difference $\tau$, that is to say, once $\left\langle\hat{a}^\dagger(t)\hat{a}(t)\right\rangle$ is stable after a certain amount of time, let's say at $t=t_{stable}$, we have the following relation:
\begin{equation}
\left\langle\hat{a}^\dagger(t_1 + t_{stable})\hat{a}_{t_2 + t_{stable}}\right\rangle = \left\langle\hat{a}^\dagger(t_1)\hat{a}_{t_2}\right\rangle
\end{equation}
hence, $\left\langle\hat{a}^\dagger(t_{stable})\hat{a}_{t_{stable}}\right\rangle$ becomes the initial value of \eqref{g1_explicit_cumu}. Obviously, the same argmuent applies for the whole system of differential equations.

Similarly, equivalent steps allow us to compute $g^2$. Indeed, this time the desired differential equation reads:
\begin{equation}
\frac{d}{dt_1} \left(\hat{a}^\dagger_{t_2}\hat{a}^\dagger(t_1)\hat{a}(t_1)\hat{a}_{t_2}\right) = \hat{a}^\dagger_{t_2} \left(\frac{d}{dt_1} \hat{a}^\dagger(t_1)\hat{a}(t_1)\right)\hat{a}_{t_2}
\end{equation}
which leads to calulate the differential equation (hence, the complete set of differential equation) for:
\begin{equation}
\frac{d}{dt} \left(\hat{a}^\dagger(t)\hat{a}(t)\right)
\end{equation}
then multiplying the full set on the left by $\hat{a}^\dagger_{t_2}$ and on the right by $\hat{a}_{t_2}$ before doing the quantum measurement (i.e applying the brackets). The initial values are computed from a complete set of equation involving:
\begin{equation}
\label{init_g2}
\left\langle\hat{a}^\dagger(t)\hat{a}^\dagger(t)\hat{a}(t)\hat{a}(t)\right\rangle
\end{equation}
Again, this allows time evolution only when $t_1\geqslant t_2$ for non-stationary process whereas we need to reach the steady-state of the set of differential equation involving \eqref{init_g2} in order to get the stable values hence a stationary process for $g^2(\tau)$.

In general, if one wants to numerically simulate the behavior of $g^1$ and $g^2$ of the quantum system (stationary or not), it is necessary to generate a complete set of equation at a minimum order of $m=5$ (i.e maximum four operators inside the correlation variables). From this set of equation, one must generate another set by multiplying the first set with $\hat{a}_{t_2}$ by the right. Finally, the last set is generated from the second one by mutliplying it with $\hat{a}^\dagger_{t_2}$ by the left. At the end of the day, one gets three independent complete set of differential equation of order, at least, $m=5$, $m=6$ and $m=7$. \footnote{The variable $m$ is \textit{artificially} incremented by one each time as the correlation variables get an additional operator constant: we do not derive explicitely a set with $m=6$ and $m=7$.}

\chapter{Heterodyne experiment}
\section{Standard setup for $g^1$ and its limitations}
\paragraph{}

In this section, we shall describe a standard method of measuring the frist order correlation function of a given classical electric field. This is meant to introduce some concepts of wave mixing, intensity detection and noise limit. Some detection properties are limited in the present case and this give a justification of the setup used in the actual experiment for measuring $g^1$.

Firstly, let's consider a linearly poilarized electric field $E_1(x, t)$ in its phasor representation as in equation \eqref{eq1} where we droped the vector sign as the field can be described only by its amplitude. Note that at this point, we do not make any hypothesis about the frequencies bearing by this field except that the field is quasi-monochromatic (i.e the linewidth of the emited light is not null around the main frequency beat). This field is our field of interest, that is to say, we want to extract coherence information from it. Thereby, we mix it with another field $E_2(x, t)$ which trivially gives a total field of:
\begin{equation}
E_{total} = E_1 + E_2
\end{equation}
Now, we place a detector at $x=0$ relatively to the total field. However, to highlight the phase difference from a field to another at the detector, we write the second electric field with a time delay $\tau$. In the classical view, the role of the detector is to transform a mean light intensity (i.e an amount of photon) into an electric intensity (i.e an amount of electron). With certain hypothesis \footnote{See section ?? (Data analysis)} one may approximate the intensity as:
\begin{align}
\begin{split}
I_{total}(t, \tau) \simeq \vert\overline{E}_{total}(t)\vert^2 &= (\overline{E}_1(t) + \overline{E}_2(t + \tau))(\overline{E}_1^*(t) + \overline{E}_2^*(t + \tau))\\
&= \vert \overline{E}_1(t) \vert^2 + \vert \overline{E}_2(t + \tau) \vert^2 + 2\Re\left\lbrace \overline{E}_1(t)\overline{E}_2^*(t + \tau)\right\rbrace
\end{split}
\end{align}
that we may rewrite for simplicity:
\begin{equation}
I_{total}(t, \tau) = I_1(t) + I_2(t + \tau) + 2\Re\left\lbrace \overline{E}_1(t) \overline{E}_2^*(t + \tau)\right\rbrace
\end{equation}
where the approximation sign is implicit.

Then, we assume that the dectector transfer exactly $100\% $ of the received light into the eletric wire (i.e quantum efficiency $\eta = 1$) and that the collected intensity is the mean value of the total intensity for an interval of time $T$:
\begin{equation}
I_{detected}(\tau) = \left\langle I_{total}(t) \right\rangle_T = \left\langle I_1(t) \right\rangle_T + \left\langle I_2(t + \tau) \right\rangle _T + 2\left\langle \Re\left\lbrace \overline{E}_1(t) \overline{E}_2^*(t + \tau)\right\rbrace \right\rangle _T
\end{equation}
with:
\begin{equation}
\left\langle \cdot \right\rangle _T = \int_T \cdot \,\,dt
\end{equation}

We introduce the correlation variable:
\begin{equation}
\label{gamma_corr_def}
\gamma_{1,2}(\tau) \stackrel{\text{def}}{=} \frac{\left\langle E_1(t) E_2^*(t + \tau) \right\rangle _T}{\sqrt{\left\langle I_1(t) \right\rangle_T \left\langle I_2(t + \tau) \right\rangle _T }} \in \mathbb{C}
\end{equation}
This previous definition transforms $I_{detected}$ as:
\begin{equation}
I_{detected} = I_1 + I_2 + 2\sqrt{I_1 I_2} \Re \left\lbrace \gamma_{1,2} \right\rbrace
\end{equation}
where we interchanged $\Re \left\lbrace \cdot \right\rbrace$ with $\left\langle \cdot \right \rangle$ \footnote{In other words, the mean value of the real part is equivalent to the real part of the mean value, by linearity.} and where we dropped the time dependences of the intensity terms (from integration, those terms becomes constant according to the time $t$).
By its normalization factor (i.e the denominator in \eqref{gamma_corr_def}), one may say that the norm of gamma is included between $0$ and $1$ where $0$ holds for complete incoherence whereas $1$ holds for full coherence. This means that we can write two extrema:
\begin{align}
I_{detected, max} &= I_1 + I_2 + 2\sqrt{I_1 I_2} \vert \gamma_{1,2} \vert\\
I_{detected, min} &= I_1 + I_2 - 2\sqrt{I_1 I_2} \vert \gamma_{1,2} \vert
\end{align}
Moreover, we define a last variable $\nu$ called the \textit{visibility}\footnote{Sometimes, $\nu$ is named the \textit{fringes visibility} in order to recall the peridicity involved in interference experiments.}:
\begin{align}
\nu \stackrel{\text{def}}{=} \frac{I_{max} - I_{min}}{I_{max} + I_{min}}
\end{align}
which represents the maximal contrast that one may observe for an intensity signal. From the dectector point of view, that is to say, the visibility of the electric signal after the wire reads:
\begin{align}
\nu = \frac{I_{detected, max} - I_{detected, min}}{I_{detected, max} + I_{detected, min}} = \frac{2\sqrt{I_1 I_2} \vert \gamma_{1,2} \vert}{I_1 + I_2}
\end{align}
In other words, the visibility two mixed electric field is proportional to the coherence term $\left\langle E_1(t) E_2^*(t + \tau) \right\rangle _T$.

Now, we make two final hypothesis:
\begin{itemize}
	\item The second electric field is coming from the same source as the first one: $E_1 = E_2 = E$. However, the two field are still delayed from each other by a time $\tau$. Experimentally, this may be reproduced with a simple Michelson interferometer which allows to vary the delay thanks to the difference of the optic path length of the two arms.
	\item The the mean value of the total intensity $I_{total}$ is constant over the time. This assumption is not necessarily obvious in a sense that our previous development could involve pulses of light, gaussian envelopes, etc. However this hypothesis lets us write that the detected intensity does not vary with time, hence the mean of interval lengths $T$ taken at  different origins give the same value: $\left\langle I(t) \right\rangle_T = \left\langle I(t + \tau) \right\rangle _T$.
\end{itemize}
At the end of the day, we obtain:
\begin{equation}
\nu = \vert \gamma_{1, 2} \vert = \frac{\vert\left\langle E(t) E^*(t + \tau) \right\rangle _T\vert}{\vert I \vert} = \vert g^1(\tau) \vert
\end{equation}
that is to say, for a quasi-monochromatic input field, the detection of the output field of a Michelson interferometer gives the norm of the first order correlation function through the connected oscilloscope. Then, varying the path length difference allows to sketch the norm of $g^1$ according to the time delay $\tau$.


\end{document}